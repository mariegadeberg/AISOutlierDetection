import pandas as pd
import matplotlib.pyplot as plt
import pickle
import seaborn as sns
import argparse
import numpy as np

parser = argparse.ArgumentParser()

parser.add_argument("--output_file", type=str, default="/trained_models/CVAE/bh30_noBN/output_30bh.txt", help="path to the output file generated by the model")
parser.add_argument("--save_fig", type=str, default="True", choices={"False", "True"}, help="whether to save the figures or not")
parser.add_argument("--save_path", type=str, default="Figures/", help="path to directory in which the figures are saved")
parser.add_argument("--model_type", type=str, default="CVAE", help="Whether it is the CVAE model or VRNN model")
parser.add_argument("--BN", type=str, default="False", help="whether BN was used in training. If yes validation should be omitted from VRNN plots")
parser.add_argument("--gradient_path", type=str, default="/trained_models/CVAE/bh30_noBN/grad_30_bh.pcl", help="path to the gradients matching the model")

args = parser.parse_args()

# create booleans
if args.save_fig == "False":
    save_fig = False
elif args.save_fig == "True":
    save_fig = True
else:
    print("indicator for save_fig not known")

if args.BN == "False":
    BN = False
elif args.BN == "True":
    BN = True
else:
    print("indicator to include_val not known")

sns.set(font_scale=1)

results = pd.read_csv(args.output_file)

if args.model_type == "CVAE":
    plt.figure()
    plt.plot(results.training_elbo)
    plt.plot(results.validation_elbo)
    plt.legend([f"Training: Value at last epoch: {results.training_elbo.iloc[-1]:.4f}", "Validation"], fontsize=12)
    plt.title("ELBO During Training", fontsize=16)
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("ELBO",  fontsize=12)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    if save_fig:
        plt.savefig(args.save_path+f"elbo_{args.model_type}.eps")
    plt.show()

    plt.figure()
    plt.plot(results.training_elbo[1:])
    plt.plot(results.validation_elbo[1:])
    plt.legend([f"Training: Value at last epoch: {results.training_elbo.iloc[-1]:.4f}", "Validation"], fontsize=12)
    plt.title("ELBO During Training", fontsize=16)
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("ELBO",  fontsize=12)
    plt.xticks([1, 5, 10, 15, 20, 25, 30], fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    if save_fig:
        plt.savefig(args.save_path+f"elbo_{args.model_type}_zoom.eps")
    plt.show()
elif args.model_type == "VRNN":
    plt.figure()
    plt.plot(results.training_loss)
    if BN:
        plt.legend([f"Training: Value at last epoch: {results.training_loss.iloc[-1]:.4f}"], fontsize=12)
    else:
        plt.plot(results.validation_loss)
        plt.legend([f"Training: Value at last epoch: {results.training_loss.iloc[-1]:.4f}", "Validation"], fontsize=12)
    plt.title("Loss During Training", fontsize=16)
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("Loss",  fontsize=12)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    if save_fig:
        plt.savefig(args.save_path+f"loss_{args.model_type}BN{args.BN}.eps")
    plt.show()


plt.figure()
plt.plot(results.training_kl)
if BN:
    plt.legend([f"Value at last epoch: {results.training_kl.iloc[-1]:.4f}"], fontsize=12)
else:
    plt.plot(results.validation_kl)
    plt.legend([f"Value at last epoch: {results.training_kl.iloc[-1]:.4f}", "Validation"], fontsize=12)
plt.title("KL divergence During Training", fontsize=16)
plt.xlabel("Epoch", fontsize=12)
plt.ylabel("KL divergence", fontsize=12)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
if save_fig:
    plt.savefig(args.save_path+f"kl_{args.model_type}BN{args.BN}.eps")
plt.show()

if args.model_type == "CVAE":
    plt.figure()
    plt.plot(results.training_kl[1:])
    plt.plot(results.validation_kl[1:])
    plt.legend([f"Value at last epoch: {results.training_kl.iloc[-1]:.4f}", "Validation"], fontsize=12)
    plt.title("KL divergence During Training", fontsize=16)
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("KL divergence", fontsize=12)
    plt.xticks([1, 5, 10, 15, 20, 25, 30],fontsize=12)
    plt.yticks(fontsize=12)
    if save_fig:
        plt.savefig(args.save_path + f"kl_{args.model_type}BN{args.BN}_zoom.eps")
    plt.show()

plt.figure()
plt.plot(results.mi)
plt.legend([f"Value at last epoch: {results.mi.iloc[-1]:.4f}"], fontsize=12)
plt.title("Mutual information", fontsize=16)
plt.xlabel("Epoch", fontsize=12)
plt.ylabel("Mutual Information", fontsize=12)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
if save_fig:
    plt.savefig(args.save_path+f"MI_{args.model_type}BN{args.BN}.eps")
plt.show()

plt.figure()
plt.plot(results.au)
plt.legend([f"Value at last epoch: {results.au.iloc[-1]}"], fontsize=12)
plt.title("Active Units", fontsize=16)
plt.xlabel("Epoch", fontsize=12)
plt.ylabel("Active Units", fontsize=12)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
if save_fig:
    plt.savefig(args.save_path+f"au_{args.model_type}BN{args.BN}.eps")
plt.show()

if args.model_type == "VRNN":

    with open(args.gradient_path, "rb") as f:
        w_ave = pickle.load(f)

    new_names = {'phi_x.0.weight': "phi_x",
                 'phi_z.0.weight': "phi_z",
                 'prior.0.weight': "Prior",
                 'encoder.0.weight': "Encoder",
                 'decoder.0.weight' : "Decoder",
                 'rnn.weight_ih_l0': "LSTM input",
                 'rnn.weight_hh_l0': "LSTM hidden"}

    y_first = w_ave[0].copy()
    y_last = w_ave[29].copy()

    y_first = dict((new_names[key], value) for (key, value) in y_first.items())
    y_last = dict((new_names[key], value) for (key, value) in y_last.items())

    legend = []
    plt.figure()
    for name in y_first.keys():
        plt.plot(y_first[name])
        legend.append([name])
    plt.title("95th Quantile of Gradients \n Through First Epoch of Training",  fontsize=16)
    plt.legend(legend,  fontsize=10)
    plt.xlabel("Steps",  fontsize=12)
    plt.ylabel("Parameter value",  fontsize=12)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    if save_fig:
        plt.savefig(args.save_path+f"gradient_flow_{args.model_type}BN{args.BN}first.eps")
    plt.show()

    legend = []
    plt.figure()
    for name in y_last.keys():
        plt.plot(y_last[name])
        legend.append([name])
    plt.title("95th Quantile of Gradients \n Through Last Epoch of Training",  fontsize=16)
    plt.legend(legend,  fontsize=10)
    plt.xlabel("Steps",  fontsize=12)
    plt.ylabel("Parameter value",  fontsize=12)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    if save_fig:
        plt.savefig(args.save_path+f"gradient_flow_{args.model_type}BN{args.BN}last.eps")
    plt.show()


#with open("/Volumes/MNG/HPCoutputs/models/bh30_norminput_BN/grad_lstm_30_bh.pcl", "rb") as f:
#    w_lstm = pickle.load(f)
#
#legend = []
#plt.figure()
#for name in w_lstm[29].keys():
#    #if name == "phi_z.0.weight" or name == "phi_x.0.weight" or name == "prior.0.weight":
#    #    continue
#    plt.plot(w_lstm[29][name])
#    legend.append([name])
#plt.title("95th percentile of gradients of LSTM in last epoch",  fontsize=16)
#plt.legend(legend,  fontsize=10)
#plt.xlabel("Steps",  fontsize=12)
#plt.ylabel("Parameter value",  fontsize=12)
#plt.xticks(fontsize=12)
#plt.yticks(fontsize=12)
##plt.ylim(-0.01, 0.01)
##plt.savefig("../Figures/gradient_flow_BNfirst.eps")
#plt.show()
#
#
#with open("../HPCoutputs/models/bh_small100epoch/diagnostics_100_bh.pcl", "rb") as f:
#    d2 = pickle.load(f)
#
#
#with open("/Volumes/MNG/models/diagnostics_5_bh.pcl", "rb") as f:
#    d2 = pickle.load(f)
#
#plt.figure()
#plt.plot(d2[50]["kl"])
#plt.title("KL development through random chosen path")
#plt.show()
#
#plt.figure()
#plt.plot(d2[0]["log_px"].sum(axis=2))
#plt.title("Log_px development through random chosen path")
#plt.show()
#
#plt.figure()
#plt.plot(d2[99]["h"][:,:])
#plt.title("h development through random chosen path")
#plt.show()
#
#plt.figure()
#plt.plot(d2[4]["mu_prior"].mean(axis=1), 'b')
#plt.plot(d2[4]["mu_post"].mean(axis=1), 'r')
#plt.legend(["Prior", "Posterior"])
#plt.title("Mean of batch means from distributions through timesteps")
#plt.show()
#
#with open("/Volumes/MNG/models/diagnostics_1_bh.pcl", "rb") as f:
#    d2 = pickle.load(f)
#
#
#lat_cols = pd.Float64Index(np.round(Config.lat_columns["bh"], 2))
#long_cols = pd.Float64Index(np.round(Config.long_columns["bh"], 2))
#
#breaks = (201, 201+402, 201+402+31)
#
#lat_out = []
#long_out = []
#for i in range(len(d2[0]["log_px"])):
#    t = d2[0]["log_px"][i,0,:]
#    lat, long, sog, cog = np.split(t, breaks)
#    lat_out.append(lat_cols[np.argmax(lat)])
#    long_out.append(long_cols[np.argmax(long)])
#
#plt.figure()
#plt.plot(long_out, lat_out, ".-")
#plt.show()
#
#import torch
#
#state_dict = torch.load("../HPCoutputs/models/bh_small100epoch/vrnn_bh100_epochs.pt", map_location=torch.device('cpu'))
#